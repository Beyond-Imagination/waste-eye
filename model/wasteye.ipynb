{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wasteye.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1AKTj4eWBzGv1zKJEekE-GAz8Cr-Xtq4r","authorship_tag":"ABX9TyO0W/vtf0D/1UwxLK4/yIde"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvJiDxP-iW06","executionInfo":{"status":"ok","timestamp":1633991144638,"user_tz":-540,"elapsed":1251,"user":{"displayName":"Y C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07392531990181495537"}},"outputId":"56f78176-b538-431a-ea7a-69ae0124b0c5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"tz5md7YWi5c9"},"source":["from torch import nn\n","\n","class WasteyeModel(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(WasteyeModel, self).__init__()\n","        def conv_bn(inp, oup, stride):\n","            return nn.Sequential(\n","                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n","                nn.BatchNorm2d(oup),\n","                nn.ReLU(inplace=True)\n","            )\n","        def conv_dw(inp, oup, stride):\n","            return nn.Sequential(\n","                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n","                nn.BatchNorm2d(inp),\n","                nn.ReLU(inplace=True),\n","    \n","                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(oup),\n","                nn.ReLU(inplace=True),\n","            )\n","        self.num_classes = num_classes\n","        self.model = nn.Sequential(\n","            conv_bn(  3,  16, 2), \n","            conv_dw( 16,  32, 1),\n","            conv_dw( 32, 64, 2),\n","            conv_dw(64, 64, 1),\n","            conv_dw(64, 128, 2),\n","            conv_dw(128, 128, 1),\n","            conv_dw(128, 256, 2),\n","            conv_dw(256, 256, 1),\n","            conv_dw(256, 512, 2),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 1024, 1)\n","        )\n","        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(1024, self.num_classes)\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = self.gap(x)\n","        x = x.view(-1, 1024)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NgOQJmhi5e_"},"source":["import torch\n","\n","#hyp parameters\n","dataset_path = \"/content/drive/My Drive/Colab Notebooks/wasteye/\"\n","model_weight_save_path = \"/content/drive/My Drive/Colab Notebooks/wasteye/model/\"\n","num_classes = 30\n","batch_size = 16\n","num_workers = 8\n","lr = 1e-3\n","\n","total_epoch = 30\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTgYGt7Ni5hq","executionInfo":{"status":"ok","timestamp":1633991197473,"user_tz":-540,"elapsed":6872,"user":{"displayName":"Y C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07392531990181495537"}},"outputId":"8408478f-04e8-453a-f260-ae3024782519"},"source":["import torch\n","from torch.utils.data import DataLoader\n","from torch import nn\n","from torchvision import transforms\n","import torchvision.datasets as datasets\n","import os\n","\n","\n","# Data loading code\n","traindir = os.path.join(dataset_path, 'train')\n","testdir = os.path.join(dataset_path, 'test')\n","\n","# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","#                                   std=[0.229, 0.224, 0.225])\n","\n","train_dataset = datasets.ImageFolder(\n","    traindir,\n","    transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        #normalize,\n","    ]))\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True,\n","    num_workers=num_workers, pin_memory=True, drop_last=False)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.ImageFolder(testdir, transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        #normalize,\n","    ])),\n","    batch_size=batch_size, shuffle=False,\n","    num_workers=num_workers, pin_memory=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"3pHp1gsyi5jZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633991199706,"user_tz":-540,"elapsed":556,"user":{"displayName":"Y C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07392531990181495537"}},"outputId":"014e7ace-187a-46cc-8878-f3bbe5deeeea"},"source":["model = WasteyeModel(num_classes).to(device)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WasteyeModel(\n","  (model): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n","      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (2): Sequential(\n","      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (3): Sequential(\n","      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (4): Sequential(\n","      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (5): Sequential(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (6): Sequential(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (7): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (8): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (9): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (10): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=1024, out_features=30, bias=True)\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"QuyaxsWNmeWO"},"source":["CEloss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3l2QuprGmeYv"},"source":["import numpy as np\n","\n","total_iteration_per_epoch = int(np.ceil(len(train_dataset)/batch_size))\n","\n","for epoch in range(1, total_epoch + 1):\n","    model.train()\n","    for itereation, (input, target) in enumerate(train_loader):\n","        images = input.to(device)\n","        labels = target.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = CEloss(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        print('Epoch [{}/{}], Iteration [{}/{}] Loss: {:.4f}'.format(epoch, total_epoch, itereation+1, total_iteration_per_epoch, loss.item()))\n","    if epoch % 10 == 0:\n","      torch.save(model.state_dict(), model_weight_save_path + '12_model_' + str(epoch) + \".pth\")\n","    \n","    model.eval()\n","    with torch.no_grad():\n","      correct = 0\n","      total = 0\n","      for input, target in test_loader:\n","          images = input.to(device)\n","          labels = target.to(device)\n","\n","          # Forward pass\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += len(labels)\n","          correct += (predicted == labels).sum().item()\n","\n","      print('Epoch [{}/{}], Test Accuracy of the model on the {} test images: {} %'.format(epoch, total_epoch, total, 100 * correct / total))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJtp_kSEmiaN","executionInfo":{"elapsed":275,"status":"ok","timestamp":1633842507614,"user":{"displayName":"Y C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07392531990181495537"},"user_tz":-540},"outputId":"857e33fc-526e-4e29-9abf-815731732240"},"source":["total_epoch"],"execution_count":null,"outputs":[{"data":{"text/plain":["30"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"vDSlBgnImeax"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvEqJ8tKmec_"},"source":[""],"execution_count":null,"outputs":[]}]}